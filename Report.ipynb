{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rahul Khanna\n",
    "\n",
    "rahulkha@usc.edu\n",
    "\n",
    "No team members\n",
    "\n",
    "USC ID: 1599870732\n",
    "\n",
    "Used Github to submit code\n",
    "\n",
    "# Exploring BERT's Transfer Learning abilities in the hope of creating a more efficient TableBERT\n",
    "\n",
    "Disclaimer: My initial idea was to explore an Active Learning approach to solve a claim entailment problem, this turned out to be quite an undertaking--mainly due to computational limitations. However, my main interest behind this approach was to optimize around efficiency, and so in this same vein I look at another efficiency optimization idea. I wanted to see if there was a real benefit to fine-tuning the whole Bert-Base-Multilingual-Cased model, or just the last classifier bit. If the performance is similar then it is much more efficient to just train the final classifier layer.\n",
    "\n",
    "Ideas Explored: Freezing Layers, Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "The dataset I choose to explore is the Tab-Fact Dataset, which was put together by some researchers at UCSB and the Tencent AI Lab in Seattle. The problem goes is as follows, given a statement and a table from a relational database, can one build a classifier to determine if the statement is true or false. The dataset that is provided gurantees that the facts needed to prove or disprove the statement lie within the given table.\n",
    "The data for this task can be found here: https://tabfact.github.io/. I will be referencing the paper associated with this dataset, TabFact, and one of their solutions, TableBERT, throughout this report.\n",
    "\n",
    "I am framing this problem as a binary classification problem, where given two inputs (the statement and the table) I must produce either a 1 - the statement is True, or a 0 - the statement is false. My goal will be to first replicate the TableBert results shown in the paper, and then slightly adapt TableBERT to allow for freezing of all BERT Layers. Once I have done this I will look at how well the frozen version of TableBERT does in comparison to the full TableBERT.\n",
    "\n",
    "The ways I will compare the two:\n",
    "\n",
    "    Accuracy over training points shown\n",
    "\n",
    "    Accuracy over time\n",
    "\n",
    "I am looking to explore if the frozen version of TableBERT is more efficient in either of these two categories. If so, one could argue using the frozen version of TableBert is a better idea, as it is the simpler version of the two and it achieves similar accuracy more efficiently than the full TableBERT. This in turn would show a strong amount of transfer learning is possible between the original Masked Language Modeling and Sequence Relationship task BERT is trained on and my current statement entailment task.\n",
    "\n",
    "I also built out functionality for using RoBERTa, but due to time and computional constraints have not run experiments using that mode. \n",
    "\n",
    "I will also be using the provided Dev and Train splits by the TabFact paper, here is what the split looks like in terms of number of examples.\n",
    "\n",
    "Data Split:\n",
    "    \n",
    "    Train: 90,232\n",
    "    \n",
    "    Dev:   12,791\n",
    "\n",
    "One of the TabFact authors (Wenhu Chen at UCSB) has uploaded the [code](https://github.com/wenhuchen/Table-Fact-Checking) used for the experiments in TabFact, as well as a checked in version of the best preforming TableBERT experiment. I will be heavily relying on his code, which in turn relies on the [examples](https://github.com/huggingface/transformers/tree/master/examples) provided by The HuggingFace company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: TableBERT\n",
    "BERT is primarily a transformer based Language Model, that can give contextualized embeddings for a word based on the words around it. This means that each word is not stuck with a single embedding, rather a word's embedding changes depending on its context. This fits nicely with the concept of word senses as many words have many senses, and forcing one single vector to capture all those senses is much more difficult than allowing for multiple vectors. BERT's contextualized embeddings have shown to be extremely powerful in many downstream tasks, including sequence pair classification (Q-A tasks, QQp task). \n",
    "\n",
    "TableBERT is an adaptation of the sequence pair classification task which BERT has been trained on. BERT's first training is done on the Language Modeling task, but it is also trained on the task of predicting if two sequences are neighbors in a larger body of text. The way BERT is used in this classification task is you append the two sequences together in the following way:\n",
    "\n",
    "    [cls]sequence_a[sep]sequence_b[sep]\n",
    "\n",
    "You then extract the hidden vector of the special CLS token of the last layer of BERT and train a classifier that takes in this hidden state and outputs your final predictions. For simplicity this final classifier is usually a single liner layer that projects the 768 dimension BERT embedding to a **c** dimensional space where an argmax is used to discern what the label should be. C is the number of classes you are labeling over. I would like to point out though that it can be whatever you'd like it to be. In the case of TableBERT it is standard single linear layer.\n",
    "\n",
    "In the context of this statement entailment task, TableBERT treats sequence_a as the task and sequence_b as a strung together representation of the table. The order of fact vs table actually matters very little, so to stay consistent with their checked in model I will be following this ordering, even though according to their paper they claim table then statement works better. The stated difference in performance is 0.1%.\n",
    "\n",
    "As the table is not a natural language sequence, the performance of this type of approach to the problem is heavily reliant on the methodology of converting the table into a sequence. The TabFact authors decided to follow a very basic template filling process where the table is broken down into one long string of decently coherent sentences describing each row. So if a table had **N** rows the sequence representing the table would look like:\n",
    "\n",
    "    template_for_row_1.template_for_row_2....template_for_row_n.\n",
    "    \n",
    "    The template per table is fixed.\n",
    "\n",
    "The paper tried other methods, but this horizontal scan of the table along with the template filling was the approach they found worked best. This makes sense as these tables are relational, so there is some sort of relation between the columns, therefore there should hypothetically exists some sort of template to string together the information in a row for any given table. Of course the approach taken isn't to fit an exact template to each table, but there are some simple rules it follows so that every table doesn't have to follow the same template. It is important when using BERT for classification purposes that you mimic as closely as possible the initial training task BERT was trained on (true for any type of transfer learning), so it is not a surprise this methodolgy worked better than their other efforts.\n",
    "\n",
    "In training TableBERT, the authors opted to update all parameters of BERT during training, which is quite an expensive task. In fact their optimal results were found while only going through half the training points, so not even a whole epoch. They used a batch size of 6 (due to memory constraints) and a learning rate of 5*e^-5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How I went about the problem\n",
    "\n",
    "In trying to replicate the paper's approach I noticed how expensive it was to train all the parameters of BERT. I was using a NVIDIA Tesla K80 GPU, and I initially ran into problems with batch sizes. The largest batch size I could use for replication purposes was 6, which I confirmed with the author was their default due to memory constraints. I feel that a batch size of 6 is increadibly small, and the gradient gained from just 6 training points out of the possible 90,232 training datapoints can't be a great representation of the overall gradient––meaning that the direction the weights are being updated in are probably often wrong.\n",
    "\n",
    "When I finally got the training started, I quickly realized one epoch of training, with periodic evaluations, would require over 14 hours of training. I also then realized that the paper's best results were achieved without even an epoch's worth of training. Again I found this odd, as the model is not being shown all examples available, so I feel that there is something strange with this training process. In fact it actually hurts the model to see all the examples, you can see a graph on the TabFact github page that shows a sharp deterioation of performance as the first epoch comes to an end. \n",
    "\n",
    "I found the whole replication experience to be quite an inhibiting aspect of using BERT to help solve problems. If you have various downstream tasks that you'd like to use BERT for, to train multiple different BERT based models would take a lot of computation power as well as time. Now some of this time / required computational power has to be accepted as even in the evaluation step it takes roughly 15 minutes for a BERT based model to go through the 12K training points. However, as I was thinking about how I could speed up this training / replicatin process I realized that I could just use BERT as an encoder, instead of trying to update it's weights. There is no gurantee that this representation will be useful, but as I started reading online I quickly found that the concept of \"freezing\" layers while training large models existed. Freezing layers essentially amounts to allowing certain layers' weights to be updated using gradient descent in training, while stopping other layers' weights from being updated. From an engineering point of view, I could just freeze all of BERT's layers and then just update the final projection matrix to one that fit my entailment task. This would severly cut down the number of weights I had to train, from 110M + 768\\*2 paramaters to just 728\\*2 parameters, well over a 99% reduction in the number of parameters needing an update. \n",
    "\n",
    "This concept of just using BERT as an encoder is exactly why BERT became such a popular and groundbreaking model in the NLP community, the model allows for transfer learning in NLP. This is shown by the various serious improvements of using BERT as an encoder for other NLP tasks (i.e not the Masked Language Model task that it is primarily trained on). Hence I figured I'd explore what amount of transfer learning is possible in this statement entailment task.\n",
    "\n",
    "It is also not unreseasonable to assume that information learned from the language model task as well as the sentence relationship task will not be helpful to a model in being able to discern whether a given statement is true or not based on facts. The statement verification task requires understanding (Language Modeling can help here), and some sort of relationship encoding between pieces of information (Sentence Relationship task can help here). However, I can also see downfalls to using BERT as an encoding layer as a claim might just be written really well and due to the heavy training of BERT on the Language Modeling task the model might think the statement is true––BERT might think its just evaluating if the statement looks gramatical or not, instead of true or not.\n",
    "\n",
    "Regardless this idea fits really nicely with how BERT is used for classification tasks, as if I just assume that BERT does a good job of creating representation for a statement and table pair, then I can just learn a good projection matrix in order to classify the representation as being one that representents a statement that is true vs false. In the more classical ML concept, its like you have 768 features and you're trying to find the best hyperplane that divides the feature space. The problem of finding a hyperplane in a space is obviously much simpler, hence the huge reduction in the number of parameteres needing updating.\n",
    "\n",
    "Also this might help the alleviate the problem of not being able to show TableBERT too many examples, i.e. the whole training corpus. The projection matrix can definitely improve as you go through more and more of the dataset, as long as you take into account overfitting. I try to take into account overfitting of the linear layer by using a dropout layer between BERT's output layer extraction and the final linear layer. The dropout perectange I used was 20%.\n",
    "\n",
    "I ran two experiments to see how well transfer learning would work in this statement entailment task:\n",
    "\n",
    "    1. Frozen TableBert, Batch Size 128 (largest I could do on my VM), Learning rate 5*e^-5\n",
    "    2. Frozen TableBert, Batch Size 64, Learning rate 2*e^-5\n",
    "\n",
    "I used a smaller learning rate in the second experiment as I reduced the batch size. I've read that its a good rule of thumb to do this, and I also think it makes sense as your gradient is more reliant the more points you use. I've also read that using too many points for SGD is a bad idea, but I don't think that applies in my case––I believe 128 is still considered a small batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pygal\n",
    "from IPython.display import SVG, display\n",
    "replication_results = pd.read_csv(\"TableBERT_Results.csv\")\n",
    "checked_in_code_replication_results = pd.read_csv(\"Best_TableBERT_Results.csv\")\n",
    "frozen_bert_128 = pd.read_csv(\"FrozenBert128_Results.csv\")\n",
    "frozen_bert_64 = pd.read_csv(\"FrozenBert64_Results.csv\")\n",
    "joint_time_performance = pd.read_csv(\"Joint_Time_Performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TableBERT Replication Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dev</td>\n",
       "      <td>0.6487</td>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.5943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simple_Test</td>\n",
       "      <td>0.7719</td>\n",
       "      <td>0.7862</td>\n",
       "      <td>0.4634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Complex_Test</td>\n",
       "      <td>0.5754</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.6645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Small Test</td>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.5772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dataset  Accuracy      F1    Loss\n",
       "0           Dev    0.6487  0.6867  0.5943\n",
       "1   Simple_Test    0.7719  0.7862  0.4634\n",
       "2  Complex_Test    0.5754  0.6286  0.6645\n",
       "3          Test    0.6395  0.6776  0.5994\n",
       "4    Small Test    0.6574  0.6870  0.5772"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checked_in_code_replication_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These result come from simply running the checked in model supplied by Wenhu Chen, and validating that they are indeed close to the results published in the TabFact paper. These results are in line with the [paper](https://arxiv.org/pdf/1909.02164.pdf)'s results, which can be found on page 7. Further I contacted Wenhu, and the results published in the paper are an average, so the slight deviation is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minutes Taken</th>\n",
       "      <th>Number of Steps</th>\n",
       "      <th>Number of Training Points</th>\n",
       "      <th>Dev Accuracy</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Dev Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>500</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.6203</td>\n",
       "      <td>0.6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>1000</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.6681</td>\n",
       "      <td>0.6887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>1500</td>\n",
       "      <td>9000</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.4070</td>\n",
       "      <td>0.6730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>2000</td>\n",
       "      <td>12000</td>\n",
       "      <td>0.6089</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>0.6619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>2500</td>\n",
       "      <td>15000</td>\n",
       "      <td>0.6180</td>\n",
       "      <td>0.5737</td>\n",
       "      <td>0.6454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180</td>\n",
       "      <td>3000</td>\n",
       "      <td>18000</td>\n",
       "      <td>0.6077</td>\n",
       "      <td>0.6118</td>\n",
       "      <td>0.6683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>210</td>\n",
       "      <td>3500</td>\n",
       "      <td>21000</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.6321</td>\n",
       "      <td>0.6790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>240</td>\n",
       "      <td>4000</td>\n",
       "      <td>24000</td>\n",
       "      <td>0.6364</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>270</td>\n",
       "      <td>4500</td>\n",
       "      <td>27000</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>0.6882</td>\n",
       "      <td>0.6374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>300</td>\n",
       "      <td>5000</td>\n",
       "      <td>30000</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.6691</td>\n",
       "      <td>0.5969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>330</td>\n",
       "      <td>5500</td>\n",
       "      <td>33000</td>\n",
       "      <td>0.6292</td>\n",
       "      <td>0.7052</td>\n",
       "      <td>0.6137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>360</td>\n",
       "      <td>6000</td>\n",
       "      <td>36000</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.6408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>390</td>\n",
       "      <td>6500</td>\n",
       "      <td>39000</td>\n",
       "      <td>0.6546</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>0.5940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>420</td>\n",
       "      <td>7000</td>\n",
       "      <td>42000</td>\n",
       "      <td>0.6388</td>\n",
       "      <td>0.7090</td>\n",
       "      <td>0.6018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>450</td>\n",
       "      <td>7500</td>\n",
       "      <td>45000</td>\n",
       "      <td>0.6139</td>\n",
       "      <td>0.6966</td>\n",
       "      <td>0.6242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>480</td>\n",
       "      <td>8000</td>\n",
       "      <td>48000</td>\n",
       "      <td>0.6357</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.6463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>510</td>\n",
       "      <td>8500</td>\n",
       "      <td>51000</td>\n",
       "      <td>0.6255</td>\n",
       "      <td>0.6978</td>\n",
       "      <td>0.6662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>540</td>\n",
       "      <td>9000</td>\n",
       "      <td>54000</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>0.6156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>570</td>\n",
       "      <td>9500</td>\n",
       "      <td>57000</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.6156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>600</td>\n",
       "      <td>10000</td>\n",
       "      <td>60000</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>0.7160</td>\n",
       "      <td>0.5857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>630</td>\n",
       "      <td>10500</td>\n",
       "      <td>63000</td>\n",
       "      <td>0.6325</td>\n",
       "      <td>0.7123</td>\n",
       "      <td>0.6007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>660</td>\n",
       "      <td>11000</td>\n",
       "      <td>66000</td>\n",
       "      <td>0.6547</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>0.6075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>690</td>\n",
       "      <td>11500</td>\n",
       "      <td>69000</td>\n",
       "      <td>0.6345</td>\n",
       "      <td>0.6670</td>\n",
       "      <td>0.6067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>720</td>\n",
       "      <td>12000</td>\n",
       "      <td>72000</td>\n",
       "      <td>0.6460</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>0.6100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Minutes Taken  Number of Steps  Number of Training Points  Dev Accuracy  \\\n",
       "0              30              500                       3000        0.5050   \n",
       "1              60             1000                       6000        0.5072   \n",
       "2              90             1500                       9000        0.5737   \n",
       "3             120             2000                      12000        0.6089   \n",
       "4             150             2500                      15000        0.6180   \n",
       "5             180             3000                      18000        0.6077   \n",
       "6             210             3500                      21000        0.6146   \n",
       "7             240             4000                      24000        0.6364   \n",
       "8             270             4500                      27000        0.6188   \n",
       "9             300             5000                      30000        0.6450   \n",
       "10            330             5500                      33000        0.6292   \n",
       "11            360             6000                      36000        0.6125   \n",
       "12            390             6500                      39000        0.6546   \n",
       "13            420             7000                      42000        0.6388   \n",
       "14            450             7500                      45000        0.6139   \n",
       "15            480             8000                      48000        0.6357   \n",
       "16            510             8500                      51000        0.6255   \n",
       "17            540             9000                      54000        0.6685   \n",
       "18            570             9500                      57000        0.6366   \n",
       "19            600            10000                      60000        0.6497   \n",
       "20            630            10500                      63000        0.6325   \n",
       "21            660            11000                      66000        0.6547   \n",
       "22            690            11500                      69000        0.6345   \n",
       "23            720            12000                      72000        0.6460   \n",
       "\n",
       "    Dev F1  Dev Loss  \n",
       "0   0.6203    0.6956  \n",
       "1   0.6681    0.6887  \n",
       "2   0.4070    0.6730  \n",
       "3   0.5881    0.6619  \n",
       "4   0.5737    0.6454  \n",
       "5   0.6118    0.6683  \n",
       "6   0.6321    0.6790  \n",
       "7   0.6368    0.6362  \n",
       "8   0.6882    0.6374  \n",
       "9   0.6691    0.5969  \n",
       "10  0.7052    0.6137  \n",
       "11  0.7090    0.6408  \n",
       "12  0.6586    0.5940  \n",
       "13  0.7090    0.6018  \n",
       "14  0.6966    0.6242  \n",
       "15  0.6978    0.6463  \n",
       "16  0.6978    0.6662  \n",
       "17  0.6739    0.6156  \n",
       "18  0.7146    0.6156  \n",
       "19  0.7160    0.5857  \n",
       "20  0.7123    0.6007  \n",
       "21  0.7102    0.6075  \n",
       "22  0.6670    0.6067  \n",
       "23  0.6527    0.6100  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replication_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results come from me actually trying to train TableBERT from scratch to make sure I could fully replicate the TabFact paper's TableBERT results. If you look at the reported TableBERT's performance in this [chart](https://github.com/wenhuchen/Table-Fact-Checking/blob/master/resource/trend.jpg) you can see it roughly mimics my results. The performance of my TableBERT experiments plateau at around 0.64 for the dev accuracy, and it does so around 5-6K step mark. The below graph should show this more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"pygal-chart\" id=\"chart-792f793a-46cb-4875-aa5c-930327a808fe\" viewBox=\"0 0 800 600\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><!--Generated with pygal 2.4.0 (etree) ©Kozea 2012-2016 on 2019-12-07--><!--http://pygal.org--><!--http://github.com/Kozea/pygal--><defs><style type=\"text/css\">#chart-792f793a-46cb-4875-aa5c-930327a808fe{-webkit-user-select:none;-webkit-font-smoothing:antialiased;font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace}#chart-792f793a-46cb-4875-aa5c-930327a808fe .title{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:16px}#chart-792f793a-46cb-4875-aa5c-930327a808fe .legends .legend text{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:14px}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis text{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:10px}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis text.major{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:10px}#chart-792f793a-46cb-4875-aa5c-930327a808fe .text-overlay text.value{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:16px}#chart-792f793a-46cb-4875-aa5c-930327a808fe .text-overlay text.label{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:10px}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:14px}#chart-792f793a-46cb-4875-aa5c-930327a808fe text.no_data{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:64px}\n",
       "#chart-792f793a-46cb-4875-aa5c-930327a808fe{background-color:rgba(249,249,249,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe path,#chart-792f793a-46cb-4875-aa5c-930327a808fe line,#chart-792f793a-46cb-4875-aa5c-930327a808fe rect,#chart-792f793a-46cb-4875-aa5c-930327a808fe circle{-webkit-transition:150ms;-moz-transition:150ms;transition:150ms}#chart-792f793a-46cb-4875-aa5c-930327a808fe .graph &gt; .background{fill:rgba(249,249,249,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .plot &gt; .background{fill:rgba(255,255,255,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .graph{fill:rgba(0,0,0,.87)}#chart-792f793a-46cb-4875-aa5c-930327a808fe text.no_data{fill:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .title{fill:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .legends .legend text{fill:rgba(0,0,0,.87)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .legends .legend:hover text{fill:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis .line{stroke:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis .guide.line{stroke:rgba(0,0,0,.54)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis .major.line{stroke:rgba(0,0,0,.87)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis text.major{fill:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.y .guides:hover .guide.line,#chart-792f793a-46cb-4875-aa5c-930327a808fe .line-graph .axis.x .guides:hover .guide.line,#chart-792f793a-46cb-4875-aa5c-930327a808fe .stackedline-graph .axis.x .guides:hover .guide.line,#chart-792f793a-46cb-4875-aa5c-930327a808fe .xy-graph .axis.x .guides:hover .guide.line{stroke:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis .guides:hover text{fill:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .reactive{fill-opacity:.7;stroke-opacity:.8}#chart-792f793a-46cb-4875-aa5c-930327a808fe .ci{stroke:rgba(0,0,0,.87)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .reactive.active,#chart-792f793a-46cb-4875-aa5c-930327a808fe .active .reactive{fill-opacity:.8;stroke-opacity:.9;stroke-width:4}#chart-792f793a-46cb-4875-aa5c-930327a808fe .ci .reactive.active{stroke-width:1.5}#chart-792f793a-46cb-4875-aa5c-930327a808fe .series text{fill:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip rect{fill:rgba(255,255,255,1);stroke:rgba(0,0,0,1);-webkit-transition:opacity 150ms;-moz-transition:opacity 150ms;transition:opacity 150ms}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip .label{fill:rgba(0,0,0,.87)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip .label{fill:rgba(0,0,0,.87)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip .legend{font-size:.8em;fill:rgba(0,0,0,.54)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip .x_label{font-size:.6em;fill:rgba(0,0,0,1)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip .xlink{font-size:.5em;text-decoration:underline}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip .value{font-size:1.5em}#chart-792f793a-46cb-4875-aa5c-930327a808fe .bound{font-size:.5em}#chart-792f793a-46cb-4875-aa5c-930327a808fe .max-value{font-size:.75em;fill:rgba(0,0,0,.54)}#chart-792f793a-46cb-4875-aa5c-930327a808fe .map-element{fill:rgba(255,255,255,1);stroke:rgba(0,0,0,.54) !important}#chart-792f793a-46cb-4875-aa5c-930327a808fe .map-element .reactive{fill-opacity:inherit;stroke-opacity:inherit}#chart-792f793a-46cb-4875-aa5c-930327a808fe .color-0,#chart-792f793a-46cb-4875-aa5c-930327a808fe .color-0 a:visited{stroke:#F44336;fill:#F44336}#chart-792f793a-46cb-4875-aa5c-930327a808fe .text-overlay .color-0 text{fill:black}\n",
       "#chart-792f793a-46cb-4875-aa5c-930327a808fe text.no_data{text-anchor:middle}#chart-792f793a-46cb-4875-aa5c-930327a808fe .guide.line{fill:none}#chart-792f793a-46cb-4875-aa5c-930327a808fe .centered{text-anchor:middle}#chart-792f793a-46cb-4875-aa5c-930327a808fe .title{text-anchor:middle}#chart-792f793a-46cb-4875-aa5c-930327a808fe .legends .legend text{fill-opacity:1}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.x text{text-anchor:middle}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.x:not(.web) text[transform]{text-anchor:start}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.x:not(.web) text[transform].backwards{text-anchor:end}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.y text{text-anchor:end}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.y text[transform].backwards{text-anchor:start}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.y2 text{text-anchor:start}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.y2 text[transform].backwards{text-anchor:end}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis .guide.line{stroke-dasharray:4,4}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis .major.guide.line{stroke-dasharray:6,6}#chart-792f793a-46cb-4875-aa5c-930327a808fe .horizontal .axis.y .guide.line,#chart-792f793a-46cb-4875-aa5c-930327a808fe .horizontal .axis.y2 .guide.line,#chart-792f793a-46cb-4875-aa5c-930327a808fe .vertical .axis.x .guide.line{opacity:0}#chart-792f793a-46cb-4875-aa5c-930327a808fe .horizontal .axis.always_show .guide.line,#chart-792f793a-46cb-4875-aa5c-930327a808fe .vertical .axis.always_show .guide.line{opacity:1 !important}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.y .guides:hover .guide.line,#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.y2 .guides:hover .guide.line,#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis.x .guides:hover .guide.line{opacity:1}#chart-792f793a-46cb-4875-aa5c-930327a808fe .axis .guides:hover text{opacity:1}#chart-792f793a-46cb-4875-aa5c-930327a808fe .nofill{fill:none}#chart-792f793a-46cb-4875-aa5c-930327a808fe .subtle-fill{fill-opacity:.2}#chart-792f793a-46cb-4875-aa5c-930327a808fe .dot{stroke-width:1px;fill-opacity:1}#chart-792f793a-46cb-4875-aa5c-930327a808fe .dot.active{stroke-width:5px}#chart-792f793a-46cb-4875-aa5c-930327a808fe .dot.negative{fill:transparent}#chart-792f793a-46cb-4875-aa5c-930327a808fe text,#chart-792f793a-46cb-4875-aa5c-930327a808fe tspan{stroke:none !important}#chart-792f793a-46cb-4875-aa5c-930327a808fe .series text.active{opacity:1}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip rect{fill-opacity:.95;stroke-width:.5}#chart-792f793a-46cb-4875-aa5c-930327a808fe .tooltip text{fill-opacity:1}#chart-792f793a-46cb-4875-aa5c-930327a808fe .showable{visibility:hidden}#chart-792f793a-46cb-4875-aa5c-930327a808fe .showable.shown{visibility:visible}#chart-792f793a-46cb-4875-aa5c-930327a808fe .gauge-background{fill:rgba(229,229,229,1);stroke:none}#chart-792f793a-46cb-4875-aa5c-930327a808fe .bg-lines{stroke:rgba(249,249,249,1);stroke-width:2px}</style><script type=\"text/javascript\">window.pygal = window.pygal || {};window.pygal.config = window.pygal.config || {};window.pygal.config['792f793a-46cb-4875-aa5c-930327a808fe'] = {&quot;allow_interruptions&quot;: false, &quot;box_mode&quot;: &quot;extremes&quot;, &quot;classes&quot;: [&quot;pygal-chart&quot;], &quot;css&quot;: [&quot;file://style.css&quot;, &quot;file://graph.css&quot;], &quot;defs&quot;: [], &quot;disable_xml_declaration&quot;: true, &quot;dots_size&quot;: 2.5, &quot;dynamic_print_values&quot;: false, &quot;explicit_size&quot;: false, &quot;fill&quot;: false, &quot;force_uri_protocol&quot;: &quot;https&quot;, &quot;formatter&quot;: null, &quot;half_pie&quot;: false, &quot;height&quot;: 600, &quot;include_x_axis&quot;: false, &quot;inner_radius&quot;: 0, &quot;interpolate&quot;: null, &quot;interpolation_parameters&quot;: {}, &quot;interpolation_precision&quot;: 250, &quot;inverse_y_axis&quot;: false, &quot;js&quot;: [&quot;//kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js&quot;], &quot;legend_at_bottom&quot;: true, &quot;legend_at_bottom_columns&quot;: null, &quot;legend_box_size&quot;: 12, &quot;logarithmic&quot;: false, &quot;margin&quot;: 20, &quot;margin_bottom&quot;: null, &quot;margin_left&quot;: null, &quot;margin_right&quot;: null, &quot;margin_top&quot;: null, &quot;max_scale&quot;: 16, &quot;min_scale&quot;: 4, &quot;missing_value_fill_truncation&quot;: &quot;x&quot;, &quot;no_data_text&quot;: &quot;No data&quot;, &quot;no_prefix&quot;: false, &quot;order_min&quot;: null, &quot;pretty_print&quot;: false, &quot;print_labels&quot;: false, &quot;print_values&quot;: false, &quot;print_values_position&quot;: &quot;center&quot;, &quot;print_zeroes&quot;: true, &quot;range&quot;: null, &quot;rounded_bars&quot;: null, &quot;secondary_range&quot;: null, &quot;show_dots&quot;: true, &quot;show_legend&quot;: true, &quot;show_minor_x_labels&quot;: true, &quot;show_minor_y_labels&quot;: true, &quot;show_only_major_dots&quot;: false, &quot;show_x_guides&quot;: false, &quot;show_x_labels&quot;: true, &quot;show_y_guides&quot;: true, &quot;show_y_labels&quot;: true, &quot;spacing&quot;: 10, &quot;stack_from_top&quot;: false, &quot;strict&quot;: false, &quot;stroke&quot;: true, &quot;stroke_style&quot;: null, &quot;style&quot;: {&quot;background&quot;: &quot;rgba(249, 249, 249, 1)&quot;, &quot;ci_colors&quot;: [], &quot;colors&quot;: [&quot;#F44336&quot;, &quot;#3F51B5&quot;, &quot;#009688&quot;, &quot;#FFC107&quot;, &quot;#FF5722&quot;, &quot;#9C27B0&quot;, &quot;#03A9F4&quot;, &quot;#8BC34A&quot;, &quot;#FF9800&quot;, &quot;#E91E63&quot;, &quot;#2196F3&quot;, &quot;#4CAF50&quot;, &quot;#FFEB3B&quot;, &quot;#673AB7&quot;, &quot;#00BCD4&quot;, &quot;#CDDC39&quot;, &quot;#9E9E9E&quot;, &quot;#607D8B&quot;], &quot;font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;foreground&quot;: &quot;rgba(0, 0, 0, .87)&quot;, &quot;foreground_strong&quot;: &quot;rgba(0, 0, 0, 1)&quot;, &quot;foreground_subtle&quot;: &quot;rgba(0, 0, 0, .54)&quot;, &quot;guide_stroke_dasharray&quot;: &quot;4,4&quot;, &quot;label_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;label_font_size&quot;: 10, &quot;legend_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;legend_font_size&quot;: 14, &quot;major_guide_stroke_dasharray&quot;: &quot;6,6&quot;, &quot;major_label_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;major_label_font_size&quot;: 10, &quot;no_data_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;no_data_font_size&quot;: 64, &quot;opacity&quot;: &quot;.7&quot;, &quot;opacity_hover&quot;: &quot;.8&quot;, &quot;plot_background&quot;: &quot;rgba(255, 255, 255, 1)&quot;, &quot;stroke_opacity&quot;: &quot;.8&quot;, &quot;stroke_opacity_hover&quot;: &quot;.9&quot;, &quot;title_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;title_font_size&quot;: 16, &quot;tooltip_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;tooltip_font_size&quot;: 14, &quot;transition&quot;: &quot;150ms&quot;, &quot;value_background&quot;: &quot;rgba(229, 229, 229, 1)&quot;, &quot;value_colors&quot;: [], &quot;value_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;value_font_size&quot;: 16, &quot;value_label_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;value_label_font_size&quot;: 10}, &quot;title&quot;: &quot;Dev Accuracy over Steps (6 training examples per Step)&quot;, &quot;tooltip_border_radius&quot;: 0, &quot;tooltip_fancy_mode&quot;: true, &quot;truncate_label&quot;: null, &quot;truncate_legend&quot;: null, &quot;width&quot;: 800, &quot;x_label_rotation&quot;: 0, &quot;x_labels&quot;: [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000, 8500, 9000, 9500, 10000, 10500, 11000, 11500, 12000], &quot;x_labels_major&quot;: null, &quot;x_labels_major_count&quot;: null, &quot;x_labels_major_every&quot;: null, &quot;x_title&quot;: &quot;Steps Completed&quot;, &quot;xrange&quot;: null, &quot;y_label_rotation&quot;: 0, &quot;y_labels&quot;: null, &quot;y_labels_major&quot;: null, &quot;y_labels_major_count&quot;: null, &quot;y_labels_major_every&quot;: null, &quot;y_title&quot;: &quot;Dev Accuracy&quot;, &quot;zero&quot;: 0, &quot;legends&quot;: [&quot;Dev Accuracy&quot;]}</script><script type=\"text/javascript\" xlink:href=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"/></defs><title>Dev Accuracy over Steps (6 training examples per Step)</title><g class=\"graph line-graph vertical\"><rect class=\"background\" height=\"600\" width=\"800\" x=\"0\" y=\"0\"/><g class=\"plot\" transform=\"translate(80, 46)\"><rect class=\"background\" height=\"464.0\" width=\"700.0\" x=\"0\" y=\"0\"/><g class=\"axis y always_show\"><path class=\"line\" d=\"M0.000000 464.000000 h700.000000\"/><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 414.145378 h700.000000\"/><text class=\"\" x=\"-5\" y=\"417.6453775582216\">0.52</text><title>0.52</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 359.569984 h700.000000\"/><text class=\"\" x=\"-5\" y=\"363.0699835332862\">0.54</text><title>0.54</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 304.994590 h700.000000\"/><text class=\"\" x=\"-5\" y=\"308.4945895083508\">0.56</text><title>0.56</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 250.419195 h700.000000\"/><text class=\"\" x=\"-5\" y=\"253.91919548341576\">0.58</text><title>0.58</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 195.843801 h700.000000\"/><text class=\"\" x=\"-5\" y=\"199.3438014584804\">0.6</text><title>0.6</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 141.268407 h700.000000\"/><text class=\"\" x=\"-5\" y=\"144.76840743354506\">0.62</text><title>0.62</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 86.693013 h700.000000\"/><text class=\"\" x=\"-5\" y=\"90.19301340860966\">0.64</text><title>0.64</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 32.117619 h700.000000\"/><text class=\"\" x=\"-5\" y=\"35.61761938367425\">0.66</text><title>0.66</title></g></g><g class=\"axis x\"><g class=\"guides\"><path class=\"line\" d=\"M13.461538 0.000000 v464.000000\"/><text class=\"\" x=\"13.461538461538462\" y=\"479.0\">500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M42.725753 0.000000 v464.000000\"/><text class=\"\" x=\"42.725752508361204\" y=\"479.0\">1000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M71.989967 0.000000 v464.000000\"/><text class=\"\" x=\"71.98996655518395\" y=\"479.0\">1500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M101.254181 0.000000 v464.000000\"/><text class=\"\" x=\"101.25418060200668\" y=\"479.0\">2000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M130.518395 0.000000 v464.000000\"/><text class=\"\" x=\"130.5183946488294\" y=\"479.0\">2500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M159.782609 0.000000 v464.000000\"/><text class=\"\" x=\"159.78260869565216\" y=\"479.0\">3000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M189.046823 0.000000 v464.000000\"/><text class=\"\" x=\"189.04682274247492\" y=\"479.0\">3500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M218.311037 0.000000 v464.000000\"/><text class=\"\" x=\"218.31103678929767\" y=\"479.0\">4000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M247.575251 0.000000 v464.000000\"/><text class=\"\" x=\"247.57525083612043\" y=\"479.0\">4500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M276.839465 0.000000 v464.000000\"/><text class=\"\" x=\"276.83946488294316\" y=\"479.0\">5000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M306.103679 0.000000 v464.000000\"/><text class=\"\" x=\"306.10367892976586\" y=\"479.0\">5500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M335.367893 0.000000 v464.000000\"/><text class=\"\" x=\"335.3678929765886\" y=\"479.0\">6000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M364.632107 0.000000 v464.000000\"/><text class=\"\" x=\"364.6321070234113\" y=\"479.0\">6500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M393.896321 0.000000 v464.000000\"/><text class=\"\" x=\"393.8963210702341\" y=\"479.0\">7000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M423.160535 0.000000 v464.000000\"/><text class=\"\" x=\"423.1605351170569\" y=\"479.0\">7500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M452.424749 0.000000 v464.000000\"/><text class=\"\" x=\"452.4247491638796\" y=\"479.0\">8000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M481.688963 0.000000 v464.000000\"/><text class=\"\" x=\"481.68896321070235\" y=\"479.0\">8500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M510.953177 0.000000 v464.000000\"/><text class=\"\" x=\"510.9531772575251\" y=\"479.0\">9000</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M540.217391 0.000000 v464.000000\"/><text class=\"\" x=\"540.2173913043479\" y=\"479.0\">9500</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M569.481605 0.000000 v464.000000\"/><text class=\"\" x=\"569.4816053511705\" y=\"479.0\">100…</text><title>10000</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M598.745819 0.000000 v464.000000\"/><text class=\"\" x=\"598.7458193979933\" y=\"479.0\">105…</text><title>10500</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M628.010033 0.000000 v464.000000\"/><text class=\"\" x=\"628.0100334448159\" y=\"479.0\">110…</text><title>11000</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M657.274247 0.000000 v464.000000\"/><text class=\"\" x=\"657.2742474916388\" y=\"479.0\">115…</text><title>11500</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M686.538462 0.000000 v464.000000\"/><text class=\"\" x=\"686.5384615384615\" y=\"479.0\">120…</text><title>12000</title></g></g><g class=\"series serie-0 color-0\"><path class=\"line reactive nofill\" d=\"M13.461538 455.076923 L42.725753 449.073630 71.989967 267.610445 101.254181 171.557751 130.518395 146.725947 159.782609 174.832275 189.046823 156.003764 218.311037 96.516584 247.575251 144.542931 276.839465 73.049165 306.103679 116.163726 335.367893 161.734180 364.632107 46.852976 393.896321 89.967537 423.160535 157.913903 452.424749 98.426723 481.688963 126.260174 510.953177 8.923077 540.217391 95.970830 569.481605 60.223947 598.745819 107.158786 628.010033 46.580099 657.274247 101.701247 686.538462 70.320395\"/></g></g><g class=\"titles\"><text class=\"title plot_title\" x=\"400.0\" y=\"26\">Dev Accuracy over Steps (6 training examples per Step)</text><text class=\"title\" x=\"430.0\" y=\"556.0\">Steps Completed</text><text class=\"title\" transform=\"rotate(-90 0.000000 278.000000)\" x=\"0\" y=\"304.0\">Dev Accuracy</text></g><g class=\"plot overlay\" transform=\"translate(80, 46)\"><g class=\"series serie-0 color-0\"><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"13.461538461538462\" cy=\"455.0769230769231\" r=\"2.5\"/><desc class=\"value\">0.505</desc><desc class=\"x top\">13.461538461538462</desc><desc class=\"y top\">455.0769230769231</desc><desc class=\"x_label\">500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"42.725752508361204\" cy=\"449.07362973418026\" r=\"2.5\"/><desc class=\"value\">0.5072</desc><desc class=\"x top\">42.725752508361204</desc><desc class=\"y top\">449.07362973418026</desc><desc class=\"x_label\">1000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"71.98996655518395\" cy=\"267.61044460127033\" r=\"2.5\"/><desc class=\"value\">0.5737</desc><desc class=\"x top\">71.98996655518395</desc><desc class=\"y top\">267.61044460127033</desc><desc class=\"x_label\">1500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"101.25418060200668\" cy=\"171.5577511173841\" r=\"2.5\"/><desc class=\"value\">0.6089</desc><desc class=\"x \">101.25418060200668</desc><desc class=\"y \">171.5577511173841</desc><desc class=\"x_label\">2000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"130.5183946488294\" cy=\"146.72594683603853\" r=\"2.5\"/><desc class=\"value\">0.618</desc><desc class=\"x \">130.5183946488294</desc><desc class=\"y \">146.72594683603853</desc><desc class=\"x_label\">2500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"159.78260869565216\" cy=\"174.8322747588802\" r=\"2.5\"/><desc class=\"value\">0.6077</desc><desc class=\"x \">159.78260869565216</desc><desc class=\"y \">174.8322747588802</desc><desc class=\"x_label\">3000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"189.04682274247492\" cy=\"156.00376382027747\" r=\"2.5\"/><desc class=\"value\">0.6146</desc><desc class=\"x \">189.04682274247492</desc><desc class=\"y \">156.00376382027747</desc><desc class=\"x_label\">3500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"218.31103678929767\" cy=\"96.51658433309814\" r=\"2.5\"/><desc class=\"value\">0.6364</desc><desc class=\"x \">218.31103678929767</desc><desc class=\"y \">96.51658433309814</desc><desc class=\"x_label\">4000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"247.57525083612043\" cy=\"144.5429310750411\" r=\"2.5\"/><desc class=\"value\">0.6188</desc><desc class=\"x \">247.57525083612043</desc><desc class=\"y \">144.5429310750411</desc><desc class=\"x_label\">4500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"276.83946488294316\" cy=\"73.04916490237582\" r=\"2.5\"/><desc class=\"value\">0.645</desc><desc class=\"x \">276.83946488294316</desc><desc class=\"y \">73.04916490237582</desc><desc class=\"x_label\">5000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"306.10367892976586\" cy=\"116.16372618207481\" r=\"2.5\"/><desc class=\"value\">0.6292</desc><desc class=\"x \">306.10367892976586</desc><desc class=\"y \">116.16372618207481</desc><desc class=\"x_label\">5500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"335.3678929765886\" cy=\"161.73418019289562\" r=\"2.5\"/><desc class=\"value\">0.6125</desc><desc class=\"x \">335.3678929765886</desc><desc class=\"y \">161.73418019289562</desc><desc class=\"x_label\">6000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"364.6321070234113\" cy=\"46.852975770407056\" r=\"2.5\"/><desc class=\"value\">0.6546</desc><desc class=\"x left\">364.6321070234113</desc><desc class=\"y left\">46.852975770407056</desc><desc class=\"x_label\">6500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"393.8963210702341\" cy=\"89.9675370501057\" r=\"2.5\"/><desc class=\"value\">0.6388</desc><desc class=\"x left\">393.8963210702341</desc><desc class=\"y left\">89.9675370501057</desc><desc class=\"x_label\">7000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"423.1605351170569\" cy=\"157.91390261115032\" r=\"2.5\"/><desc class=\"value\">0.6139</desc><desc class=\"x left\">423.1605351170569</desc><desc class=\"y left\">157.91390261115032</desc><desc class=\"x_label\">7500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"452.4247491638796\" cy=\"98.42672312397065\" r=\"2.5\"/><desc class=\"value\">0.6357</desc><desc class=\"x left\">452.4247491638796</desc><desc class=\"y left\">98.42672312397065</desc><desc class=\"x_label\">8000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"481.68896321070235\" cy=\"126.26017407668797\" r=\"2.5\"/><desc class=\"value\">0.6255</desc><desc class=\"x left\">481.68896321070235</desc><desc class=\"y left\">126.26017407668797</desc><desc class=\"x_label\">8500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"510.9531772575251\" cy=\"8.923076923076906\" r=\"2.5\"/><desc class=\"value\">0.6685</desc><desc class=\"x left\">510.9531772575251</desc><desc class=\"y left\">8.923076923076906</desc><desc class=\"x_label\">9000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"540.2173913043479\" cy=\"95.97083039284854\" r=\"2.5\"/><desc class=\"value\">0.6366</desc><desc class=\"x left\">540.2173913043479</desc><desc class=\"y left\">95.97083039284854</desc><desc class=\"x_label\">9500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"569.4816053511705\" cy=\"60.22394730651587\" r=\"2.5\"/><desc class=\"value\">0.6497</desc><desc class=\"x left\">569.4816053511705</desc><desc class=\"y left\">60.22394730651587</desc><desc class=\"x_label\">10000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"598.7458193979933\" cy=\"107.15878616796056\" r=\"2.5\"/><desc class=\"value\">0.6325</desc><desc class=\"x left\">598.7458193979933</desc><desc class=\"y left\">107.15878616796056</desc><desc class=\"x_label\">10500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"628.0100334448159\" cy=\"46.58009880028237\" r=\"2.5\"/><desc class=\"value\">0.6547</desc><desc class=\"x left\">628.0100334448159</desc><desc class=\"y left\">46.58009880028237</desc><desc class=\"x_label\">11000</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"657.2742474916388\" cy=\"101.70124676546703\" r=\"2.5\"/><desc class=\"value\">0.6345</desc><desc class=\"x left\">657.2742474916388</desc><desc class=\"y left\">101.70124676546703</desc><desc class=\"x_label\">11500</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"686.5384615384615\" cy=\"70.32039520112937\" r=\"2.5\"/><desc class=\"value\">0.646</desc><desc class=\"x left\">686.5384615384615</desc><desc class=\"y left\">70.32039520112937</desc><desc class=\"x_label\">12000</desc></g></g></g><g class=\"plot text-overlay\" transform=\"translate(80, 46)\"><g class=\"series serie-0 color-0\"/></g><g class=\"plot tooltip-overlay\" transform=\"translate(80, 46)\"><g class=\"tooltip\" style=\"opacity: 0\" transform=\"translate(0 0)\"><rect class=\"tooltip-box\" height=\"0\" rx=\"0\" ry=\"0\" width=\"0\"/><g class=\"text\"/></g></g><g class=\"legends\" transform=\"translate(90, 576)\"><g class=\"legend reactive activate-serie\" id=\"activate-serie-0\"><rect class=\"color-0 reactive\" height=\"12\" width=\"12\" x=\"0.0\" y=\"1.0\"/><text x=\"17.0\" y=\"11.2\">Dev Accuracy</text></g></g></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_chart = pygal.Line(legend_at_bottom=True)\n",
    "line_chart.title = 'Dev Accuracy over Steps (6 training examples per Step)'\n",
    "line_chart.x_title = \"Steps Completed\"\n",
    "line_chart.y_title = \"Dev Accuracy\"\n",
    "line_chart.x_labels = list(replication_results[\"Number of Steps\"])\n",
    "line_chart.add(\"Dev Accuracy\", list(replication_results[\"Dev Accuracy\"]))\n",
    "display(SVG(line_chart.render(disable_xml_declaration=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen TableBert Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 1 -- Batch Size of 128**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minutes Taken</th>\n",
       "      <th>Steps Taken</th>\n",
       "      <th>Number of Training Points</th>\n",
       "      <th>Dev Accuracy</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Dev Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>100</td>\n",
       "      <td>12800</td>\n",
       "      <td>0.5022</td>\n",
       "      <td>0.5120</td>\n",
       "      <td>0.7065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>200</td>\n",
       "      <td>25600</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.6574</td>\n",
       "      <td>0.7614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>38400</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>0.7136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>400</td>\n",
       "      <td>51200</td>\n",
       "      <td>0.5060</td>\n",
       "      <td>0.6466</td>\n",
       "      <td>0.7260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>500</td>\n",
       "      <td>64000</td>\n",
       "      <td>0.5072</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180</td>\n",
       "      <td>600</td>\n",
       "      <td>76800</td>\n",
       "      <td>0.5062</td>\n",
       "      <td>0.6721</td>\n",
       "      <td>0.8663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>210</td>\n",
       "      <td>700</td>\n",
       "      <td>89600</td>\n",
       "      <td>0.5063</td>\n",
       "      <td>0.6723</td>\n",
       "      <td>1.0539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>240</td>\n",
       "      <td>800</td>\n",
       "      <td>102400</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.6556</td>\n",
       "      <td>0.7461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>270</td>\n",
       "      <td>900</td>\n",
       "      <td>115200</td>\n",
       "      <td>0.4988</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.7130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Minutes Taken  Steps Taken  Number of Training Points  Dev Accuracy  \\\n",
       "0             30          100                      12800        0.5022   \n",
       "1             60          200                      25600        0.5062   \n",
       "2             90          300                      38400        0.5008   \n",
       "3            120          400                      51200        0.5060   \n",
       "4            150          500                      64000        0.5072   \n",
       "5            180          600                      76800        0.5062   \n",
       "6            210          700                      89600        0.5063   \n",
       "7            240          800                     102400        0.5066   \n",
       "8            270          900                     115200        0.4988   \n",
       "\n",
       "   Dev F1  Dev Loss  \n",
       "0  0.5120    0.7065  \n",
       "1  0.6574    0.7614  \n",
       "2  0.3677    0.7136  \n",
       "3  0.6466    0.7260  \n",
       "4  0.6604    0.7488  \n",
       "5  0.6721    0.8663  \n",
       "6  0.6723    1.0539  \n",
       "7  0.6556    0.7461  \n",
       "8  0.4808    0.7130  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_bert_128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 2 -- Batch Size of 64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Minutes Taken</th>\n",
       "      <th>Number of Steps</th>\n",
       "      <th>Number of Training Points</th>\n",
       "      <th>Dev Accuracy</th>\n",
       "      <th>Dev F1</th>\n",
       "      <th>Dev Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>300</td>\n",
       "      <td>19200</td>\n",
       "      <td>0.4948</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.7455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>600</td>\n",
       "      <td>38400</td>\n",
       "      <td>0.5059</td>\n",
       "      <td>0.6507</td>\n",
       "      <td>0.7189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>900</td>\n",
       "      <td>57600</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.6673</td>\n",
       "      <td>0.7596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160</td>\n",
       "      <td>1200</td>\n",
       "      <td>76800</td>\n",
       "      <td>0.5097</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.7210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>1500</td>\n",
       "      <td>96000</td>\n",
       "      <td>0.5056</td>\n",
       "      <td>0.6366</td>\n",
       "      <td>0.7159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>240</td>\n",
       "      <td>1800</td>\n",
       "      <td>115200</td>\n",
       "      <td>0.5023</td>\n",
       "      <td>0.5745</td>\n",
       "      <td>0.7086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>280</td>\n",
       "      <td>2100</td>\n",
       "      <td>134400</td>\n",
       "      <td>0.5066</td>\n",
       "      <td>0.6714</td>\n",
       "      <td>0.8470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Minutes Taken  Number of Steps  Number of Training Points  Dev Accuracy  \\\n",
       "0             40              300                      19200        0.4948   \n",
       "1             80              600                      38400        0.5059   \n",
       "2            120              900                      57600        0.5066   \n",
       "3            160             1200                      76800        0.5097   \n",
       "4            200             1500                      96000        0.5056   \n",
       "5            240             1800                     115200        0.5023   \n",
       "6            280             2100                     134400        0.5066   \n",
       "\n",
       "   Dev F1  Dev Loss  \n",
       "0  0.1246    0.7455  \n",
       "1  0.6507    0.7189  \n",
       "2  0.6673    0.7596  \n",
       "3  0.6389    0.7210  \n",
       "4  0.6366    0.7159  \n",
       "5  0.5745    0.7086  \n",
       "6  0.6714    0.8470  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozen_bert_64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So as we can see, even after over 4 hours of traning, there is no real change in performance of the overall classifier in either experiment. This highly indicates that in order to take advantage of the transfer learning offered by the BERT model we must update all the weights as done in the original TableBert implementation. It could also be that the final classifier used at the end was too simple, i.e. there was no good hyper plane that could split the space of embeddings being produced by BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graphs and tables, it is obvious that the frozen version of TableBERT can certainly not be considered a replacement for TableBERT. This means that in this current setup, in order to take advantage of the transfer learning offered by BERT, without updating the full model, we must update our classification piece to something more complex, maybe a multi-layer perceptron, for any chance of creating a more efficient version of TableBERT. There is no gurantee this will help though.\n",
    "\n",
    "It is likely that a more resource efficient solution to this problem exists, but either not using BERT or changing the way the table is encoded into a sequence. These results show that in order to take advantage of a BERT based model using a simple `table_to_sequence` method you must train at least some of the weights in the the BERT model, and not just the final simple project layer.\n",
    "\n",
    "I think from the above tables its clear that from a **number of training points shown perspective, the original TableBERT is more efficient than the versions of the frozen TableBERT**. However, because the two experiments don't have as many parameters to tune, we can process more datapoints per second, so to makes sure from a time perspective the two experiments are not more efficient than TableBERT you can look at the below graph. **In both forms of efficiency regular TableBERT is more efficient.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg class=\"pygal-chart\" id=\"chart-2566347e-f0e3-4824-a8ff-4d557465b038\" viewBox=\"0 0 800 600\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><!--Generated with pygal 2.4.0 (etree) ©Kozea 2012-2016 on 2019-12-07--><!--http://pygal.org--><!--http://github.com/Kozea/pygal--><defs><style type=\"text/css\">#chart-2566347e-f0e3-4824-a8ff-4d557465b038{-webkit-user-select:none;-webkit-font-smoothing:antialiased;font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .title{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:16px}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .legends .legend text{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:14px}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis text{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:10px}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis text.major{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:10px}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .text-overlay text.value{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:16px}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .text-overlay text.label{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:10px}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:14px}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 text.no_data{font-family:Consolas,&quot;Liberation Mono&quot;,Menlo,Courier,monospace;font-size:64px}\n",
       "#chart-2566347e-f0e3-4824-a8ff-4d557465b038{background-color:rgba(249,249,249,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 path,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 rect,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 circle{-webkit-transition:150ms;-moz-transition:150ms;transition:150ms}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .graph &gt; .background{fill:rgba(249,249,249,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .plot &gt; .background{fill:rgba(255,255,255,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .graph{fill:rgba(0,0,0,.87)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 text.no_data{fill:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .title{fill:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .legends .legend text{fill:rgba(0,0,0,.87)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .legends .legend:hover text{fill:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis .line{stroke:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis .guide.line{stroke:rgba(0,0,0,.54)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis .major.line{stroke:rgba(0,0,0,.87)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis text.major{fill:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.y .guides:hover .guide.line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .line-graph .axis.x .guides:hover .guide.line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .stackedline-graph .axis.x .guides:hover .guide.line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .xy-graph .axis.x .guides:hover .guide.line{stroke:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis .guides:hover text{fill:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .reactive{fill-opacity:.7;stroke-opacity:.8}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .ci{stroke:rgba(0,0,0,.87)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .reactive.active,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .active .reactive{fill-opacity:.8;stroke-opacity:.9;stroke-width:4}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .ci .reactive.active{stroke-width:1.5}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .series text{fill:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip rect{fill:rgba(255,255,255,1);stroke:rgba(0,0,0,1);-webkit-transition:opacity 150ms;-moz-transition:opacity 150ms;transition:opacity 150ms}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip .label{fill:rgba(0,0,0,.87)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip .label{fill:rgba(0,0,0,.87)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip .legend{font-size:.8em;fill:rgba(0,0,0,.54)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip .x_label{font-size:.6em;fill:rgba(0,0,0,1)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip .xlink{font-size:.5em;text-decoration:underline}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip .value{font-size:1.5em}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .bound{font-size:.5em}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .max-value{font-size:.75em;fill:rgba(0,0,0,.54)}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .map-element{fill:rgba(255,255,255,1);stroke:rgba(0,0,0,.54) !important}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .map-element .reactive{fill-opacity:inherit;stroke-opacity:inherit}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .color-0,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .color-0 a:visited{stroke:#F44336;fill:#F44336}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .color-1,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .color-1 a:visited{stroke:#3F51B5;fill:#3F51B5}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .color-2,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .color-2 a:visited{stroke:#009688;fill:#009688}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .text-overlay .color-0 text{fill:black}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .text-overlay .color-1 text{fill:black}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .text-overlay .color-2 text{fill:black}\n",
       "#chart-2566347e-f0e3-4824-a8ff-4d557465b038 text.no_data{text-anchor:middle}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .guide.line{fill:none}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .centered{text-anchor:middle}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .title{text-anchor:middle}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .legends .legend text{fill-opacity:1}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.x text{text-anchor:middle}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.x:not(.web) text[transform]{text-anchor:start}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.x:not(.web) text[transform].backwards{text-anchor:end}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.y text{text-anchor:end}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.y text[transform].backwards{text-anchor:start}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.y2 text{text-anchor:start}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.y2 text[transform].backwards{text-anchor:end}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis .guide.line{stroke-dasharray:4,4}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis .major.guide.line{stroke-dasharray:6,6}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .horizontal .axis.y .guide.line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .horizontal .axis.y2 .guide.line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .vertical .axis.x .guide.line{opacity:0}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .horizontal .axis.always_show .guide.line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .vertical .axis.always_show .guide.line{opacity:1 !important}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.y .guides:hover .guide.line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.y2 .guides:hover .guide.line,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis.x .guides:hover .guide.line{opacity:1}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .axis .guides:hover text{opacity:1}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .nofill{fill:none}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .subtle-fill{fill-opacity:.2}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .dot{stroke-width:1px;fill-opacity:1}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .dot.active{stroke-width:5px}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .dot.negative{fill:transparent}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 text,#chart-2566347e-f0e3-4824-a8ff-4d557465b038 tspan{stroke:none !important}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .series text.active{opacity:1}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip rect{fill-opacity:.95;stroke-width:.5}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .tooltip text{fill-opacity:1}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .showable{visibility:hidden}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .showable.shown{visibility:visible}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .gauge-background{fill:rgba(229,229,229,1);stroke:none}#chart-2566347e-f0e3-4824-a8ff-4d557465b038 .bg-lines{stroke:rgba(249,249,249,1);stroke-width:2px}</style><script type=\"text/javascript\">window.pygal = window.pygal || {};window.pygal.config = window.pygal.config || {};window.pygal.config['2566347e-f0e3-4824-a8ff-4d557465b038'] = {&quot;allow_interruptions&quot;: false, &quot;box_mode&quot;: &quot;extremes&quot;, &quot;classes&quot;: [&quot;pygal-chart&quot;], &quot;css&quot;: [&quot;file://style.css&quot;, &quot;file://graph.css&quot;], &quot;defs&quot;: [], &quot;disable_xml_declaration&quot;: true, &quot;dots_size&quot;: 2.5, &quot;dynamic_print_values&quot;: false, &quot;explicit_size&quot;: false, &quot;fill&quot;: false, &quot;force_uri_protocol&quot;: &quot;https&quot;, &quot;formatter&quot;: null, &quot;half_pie&quot;: false, &quot;height&quot;: 600, &quot;include_x_axis&quot;: false, &quot;inner_radius&quot;: 0, &quot;interpolate&quot;: null, &quot;interpolation_parameters&quot;: {}, &quot;interpolation_precision&quot;: 250, &quot;inverse_y_axis&quot;: false, &quot;js&quot;: [&quot;//kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js&quot;], &quot;legend_at_bottom&quot;: true, &quot;legend_at_bottom_columns&quot;: null, &quot;legend_box_size&quot;: 12, &quot;logarithmic&quot;: false, &quot;margin&quot;: 20, &quot;margin_bottom&quot;: null, &quot;margin_left&quot;: null, &quot;margin_right&quot;: null, &quot;margin_top&quot;: null, &quot;max_scale&quot;: 16, &quot;min_scale&quot;: 4, &quot;missing_value_fill_truncation&quot;: &quot;x&quot;, &quot;no_data_text&quot;: &quot;No data&quot;, &quot;no_prefix&quot;: false, &quot;order_min&quot;: null, &quot;pretty_print&quot;: false, &quot;print_labels&quot;: false, &quot;print_values&quot;: false, &quot;print_values_position&quot;: &quot;center&quot;, &quot;print_zeroes&quot;: true, &quot;range&quot;: null, &quot;rounded_bars&quot;: null, &quot;secondary_range&quot;: null, &quot;show_dots&quot;: true, &quot;show_legend&quot;: true, &quot;show_minor_x_labels&quot;: true, &quot;show_minor_y_labels&quot;: true, &quot;show_only_major_dots&quot;: false, &quot;show_x_guides&quot;: false, &quot;show_x_labels&quot;: true, &quot;show_y_guides&quot;: true, &quot;show_y_labels&quot;: true, &quot;spacing&quot;: 10, &quot;stack_from_top&quot;: false, &quot;strict&quot;: false, &quot;stroke&quot;: true, &quot;stroke_style&quot;: null, &quot;style&quot;: {&quot;background&quot;: &quot;rgba(249, 249, 249, 1)&quot;, &quot;ci_colors&quot;: [], &quot;colors&quot;: [&quot;#F44336&quot;, &quot;#3F51B5&quot;, &quot;#009688&quot;, &quot;#FFC107&quot;, &quot;#FF5722&quot;, &quot;#9C27B0&quot;, &quot;#03A9F4&quot;, &quot;#8BC34A&quot;, &quot;#FF9800&quot;, &quot;#E91E63&quot;, &quot;#2196F3&quot;, &quot;#4CAF50&quot;, &quot;#FFEB3B&quot;, &quot;#673AB7&quot;, &quot;#00BCD4&quot;, &quot;#CDDC39&quot;, &quot;#9E9E9E&quot;, &quot;#607D8B&quot;], &quot;font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;foreground&quot;: &quot;rgba(0, 0, 0, .87)&quot;, &quot;foreground_strong&quot;: &quot;rgba(0, 0, 0, 1)&quot;, &quot;foreground_subtle&quot;: &quot;rgba(0, 0, 0, .54)&quot;, &quot;guide_stroke_dasharray&quot;: &quot;4,4&quot;, &quot;label_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;label_font_size&quot;: 10, &quot;legend_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;legend_font_size&quot;: 14, &quot;major_guide_stroke_dasharray&quot;: &quot;6,6&quot;, &quot;major_label_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;major_label_font_size&quot;: 10, &quot;no_data_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;no_data_font_size&quot;: 64, &quot;opacity&quot;: &quot;.7&quot;, &quot;opacity_hover&quot;: &quot;.8&quot;, &quot;plot_background&quot;: &quot;rgba(255, 255, 255, 1)&quot;, &quot;stroke_opacity&quot;: &quot;.8&quot;, &quot;stroke_opacity_hover&quot;: &quot;.9&quot;, &quot;title_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;title_font_size&quot;: 16, &quot;tooltip_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;tooltip_font_size&quot;: 14, &quot;transition&quot;: &quot;150ms&quot;, &quot;value_background&quot;: &quot;rgba(229, 229, 229, 1)&quot;, &quot;value_colors&quot;: [], &quot;value_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;value_font_size&quot;: 16, &quot;value_label_font_family&quot;: &quot;Consolas, \\&quot;Liberation Mono\\&quot;, Menlo, Courier, monospace&quot;, &quot;value_label_font_size&quot;: 10}, &quot;title&quot;: &quot;Dev Accuracy over Minutes&quot;, &quot;tooltip_border_radius&quot;: 0, &quot;tooltip_fancy_mode&quot;: true, &quot;truncate_label&quot;: null, &quot;truncate_legend&quot;: null, &quot;width&quot;: 800, &quot;x_label_rotation&quot;: 0, &quot;x_labels&quot;: [30, 40, 60, 80, 90, 120, 150, 160, 180, 200, 210, 240, 270, 280], &quot;x_labels_major&quot;: null, &quot;x_labels_major_count&quot;: null, &quot;x_labels_major_every&quot;: null, &quot;x_title&quot;: &quot;Minutes&quot;, &quot;xrange&quot;: null, &quot;y_label_rotation&quot;: 0, &quot;y_labels&quot;: null, &quot;y_labels_major&quot;: null, &quot;y_labels_major_count&quot;: null, &quot;y_labels_major_every&quot;: null, &quot;y_title&quot;: &quot;Dev Accuracy&quot;, &quot;zero&quot;: 0, &quot;legends&quot;: [&quot;TableBERT&quot;, &quot;Frozen_TableBERT_1&quot;, &quot;Frozen_TableBERT_2&quot;]}</script><script type=\"text/javascript\" xlink:href=\"https://kozea.github.io/pygal.js/2.0.x/pygal-tooltips.min.js\"/></defs><title>Dev Accuracy over Minutes</title><g class=\"graph line-graph vertical\"><rect class=\"background\" height=\"600\" width=\"800\" x=\"0\" y=\"0\"/><g class=\"plot\" transform=\"translate(80, 46)\"><rect class=\"background\" height=\"443.0\" width=\"700.0\" x=\"0\" y=\"0\"/><g class=\"axis y always_show\"><path class=\"line\" d=\"M0.000000 443.000000 h700.000000\"/><g class=\"guides\"><path class=\"major guide line\" d=\"M0.000000 418.838114 h700.000000\"/><text class=\"major\" x=\"-5\" y=\"422.3381138635376\">0.5</text><title>0.5</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 388.756084 h700.000000\"/><text class=\"\" x=\"-5\" y=\"392.25608431116905\">0.51</text><title>0.51</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 358.674055 h700.000000\"/><text class=\"\" x=\"-5\" y=\"362.1740547588005\">0.52</text><title>0.52</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 328.592025 h700.000000\"/><text class=\"\" x=\"-5\" y=\"332.09202520643186\">0.53</text><title>0.53</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 298.509996 h700.000000\"/><text class=\"\" x=\"-5\" y=\"302.0099956540633\">0.54</text><title>0.54</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 268.427966 h700.000000\"/><text class=\"\" x=\"-5\" y=\"271.92796610169466\">0.55</text><title>0.55</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 238.345937 h700.000000\"/><text class=\"\" x=\"-5\" y=\"241.84593654932613\">0.56</text><title>0.56</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 208.263907 h700.000000\"/><text class=\"\" x=\"-5\" y=\"211.76390699695787\">0.57</text><title>0.57</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 178.181877 h700.000000\"/><text class=\"\" x=\"-5\" y=\"181.6818774445893\">0.58</text><title>0.58</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 148.099848 h700.000000\"/><text class=\"\" x=\"-5\" y=\"151.59984789222068\">0.59</text><title>0.59</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 118.017818 h700.000000\"/><text class=\"\" x=\"-5\" y=\"121.51781833985211\">0.6</text><title>0.6</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 87.935789 h700.000000\"/><text class=\"\" x=\"-5\" y=\"91.43578878748355\">0.61</text><title>0.61</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 57.853759 h700.000000\"/><text class=\"\" x=\"-5\" y=\"61.35375923511492\">0.62</text><title>0.62</title></g><g class=\"guides\"><path class=\"guide line\" d=\"M0.000000 27.771730 h700.000000\"/><text class=\"\" x=\"-5\" y=\"31.27172968274641\">0.63</text><title>0.63</title></g></g><g class=\"axis x\"><g class=\"guides\"><path class=\"line\" d=\"M13.461538 0.000000 v443.000000\"/><text class=\"\" x=\"13.461538461538462\" y=\"458.0\">30</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M65.236686 0.000000 v443.000000\"/><text class=\"\" x=\"65.23668639053255\" y=\"458.0\">40</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M117.011834 0.000000 v443.000000\"/><text class=\"\" x=\"117.01183431952663\" y=\"458.0\">60</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M168.786982 0.000000 v443.000000\"/><text class=\"\" x=\"168.7869822485207\" y=\"458.0\">80</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M220.562130 0.000000 v443.000000\"/><text class=\"\" x=\"220.5621301775148\" y=\"458.0\">90</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M272.337278 0.000000 v443.000000\"/><text class=\"\" x=\"272.3372781065089\" y=\"458.0\">120</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M324.112426 0.000000 v443.000000\"/><text class=\"\" x=\"324.11242603550295\" y=\"458.0\">150</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M375.887574 0.000000 v443.000000\"/><text class=\"\" x=\"375.887573964497\" y=\"458.0\">160</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M427.662722 0.000000 v443.000000\"/><text class=\"\" x=\"427.66272189349115\" y=\"458.0\">180</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M479.437870 0.000000 v443.000000\"/><text class=\"\" x=\"479.4378698224852\" y=\"458.0\">200</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M531.213018 0.000000 v443.000000\"/><text class=\"\" x=\"531.2130177514792\" y=\"458.0\">210</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M582.988166 0.000000 v443.000000\"/><text class=\"\" x=\"582.9881656804733\" y=\"458.0\">240</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M634.763314 0.000000 v443.000000\"/><text class=\"\" x=\"634.7633136094674\" y=\"458.0\">270</text></g><g class=\"guides\"><path class=\"guide line\" d=\"M686.538462 0.000000 v443.000000\"/><text class=\"\" x=\"686.5384615384615\" y=\"458.0\">280</text></g></g><g class=\"series serie-0 color-0\"><path class=\"line reactive nofill\" d=\"M13.461538 403.797099 L117.011834 397.179053 220.562130 197.133556 272.337278 91.244812 324.112426 63.870165 427.662722 94.854656 531.213018 74.098055 582.988166 8.519231 634.763314 61.463603\"/></g><g class=\"series serie-1 color-1\"><path class=\"line reactive nofill\" d=\"M13.461538 412.220067 L117.011834 400.187256 220.562130 416.431551 272.337278 400.788896 324.112426 397.179053 427.662722 400.187256 531.213018 399.886435 582.988166 398.983974 634.763314 422.447957\"/></g><g class=\"series serie-2 color-2\"><path class=\"line reactive nofill\" d=\"M65.236686 434.480769 L168.786982 401.089716 272.337278 398.983974 375.887574 389.658545 479.437870 401.992177 582.988166 411.919247 686.538462 398.983974\"/></g></g><g class=\"titles\"><text class=\"title plot_title\" x=\"400.0\" y=\"26\">Dev Accuracy over Minutes</text><text class=\"title\" x=\"430.0\" y=\"535.0\">Minutes</text><text class=\"title\" transform=\"rotate(-90 0.000000 267.500000)\" x=\"0\" y=\"293.5\">Dev Accuracy</text></g><g class=\"plot overlay\" transform=\"translate(80, 46)\"><g class=\"series serie-0 color-0\"><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"13.461538461538462\" cy=\"403.79709908735333\" r=\"2.5\"/><desc class=\"value\">0.505</desc><desc class=\"x top\">13.461538461538462</desc><desc class=\"y top\">403.79709908735333</desc><desc class=\"x_label\">30</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"117.01183431952663\" cy=\"397.1790525858323\" r=\"2.5\"/><desc class=\"value\">0.5072</desc><desc class=\"x top\">117.01183431952663</desc><desc class=\"y top\">397.1790525858323</desc><desc class=\"x_label\">60</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"220.5621301775148\" cy=\"197.13355606258142\" r=\"2.5\"/><desc class=\"value\">0.5737</desc><desc class=\"x \">220.5621301775148</desc><desc class=\"y \">197.13355606258142</desc><desc class=\"x_label\">90</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"272.3372781065089\" cy=\"91.24481203824405\" r=\"2.5\"/><desc class=\"value\">0.6089</desc><desc class=\"x \">272.3372781065089</desc><desc class=\"y \">91.24481203824405</desc><desc class=\"x_label\">120</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"324.11242603550295\" cy=\"63.87016514558866\" r=\"2.5\"/><desc class=\"value\">0.618</desc><desc class=\"x \">324.11242603550295</desc><desc class=\"y \">63.87016514558866</desc><desc class=\"x_label\">150</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"427.66272189349115\" cy=\"94.85465558452825\" r=\"2.5\"/><desc class=\"value\">0.6077</desc><desc class=\"x left\">427.66272189349115</desc><desc class=\"y left\">94.85465558452825</desc><desc class=\"x_label\">180</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"531.2130177514792\" cy=\"74.09805519339386\" r=\"2.5\"/><desc class=\"value\">0.6146</desc><desc class=\"x left\">531.2130177514792</desc><desc class=\"y left\">74.09805519339386</desc><desc class=\"x_label\">210</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"582.9881656804733\" cy=\"8.519230769230603\" r=\"2.5\"/><desc class=\"value\">0.6364</desc><desc class=\"x left\">582.9881656804733</desc><desc class=\"y left\">8.519230769230603</desc><desc class=\"x_label\">240</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"634.7633136094674\" cy=\"61.46360278139912\" r=\"2.5\"/><desc class=\"value\">0.6188</desc><desc class=\"x left\">634.7633136094674</desc><desc class=\"y left\">61.46360278139912</desc><desc class=\"x_label\">270</desc></g></g><g class=\"series serie-1 color-1\"><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"13.461538461538462\" cy=\"412.2200673620166\" r=\"2.5\"/><desc class=\"value\">0.5022</desc><desc class=\"x top\">13.461538461538462</desc><desc class=\"y top\">412.2200673620166</desc><desc class=\"x_label\">30</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"117.01183431952663\" cy=\"400.1872555410692\" r=\"2.5\"/><desc class=\"value\">0.5062</desc><desc class=\"x top\">117.01183431952663</desc><desc class=\"y top\">400.1872555410692</desc><desc class=\"x_label\">60</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"220.5621301775148\" cy=\"416.4315514993481\" r=\"2.5\"/><desc class=\"value\">0.5008</desc><desc class=\"x top\">220.5621301775148</desc><desc class=\"y top\">416.4315514993481</desc><desc class=\"x_label\">90</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"272.3372781065089\" cy=\"400.78889613211646\" r=\"2.5\"/><desc class=\"value\">0.506</desc><desc class=\"x top\">272.3372781065089</desc><desc class=\"y top\">400.78889613211646</desc><desc class=\"x_label\">120</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"324.11242603550295\" cy=\"397.1790525858323\" r=\"2.5\"/><desc class=\"value\">0.5072</desc><desc class=\"x top\">324.11242603550295</desc><desc class=\"y top\">397.1790525858323</desc><desc class=\"x_label\">150</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"427.66272189349115\" cy=\"400.1872555410692\" r=\"2.5\"/><desc class=\"value\">0.5062</desc><desc class=\"x left top\">427.66272189349115</desc><desc class=\"y left top\">400.1872555410692</desc><desc class=\"x_label\">180</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"531.2130177514792\" cy=\"399.8864352455455\" r=\"2.5\"/><desc class=\"value\">0.5063</desc><desc class=\"x left top\">531.2130177514792</desc><desc class=\"y left top\">399.8864352455455</desc><desc class=\"x_label\">210</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"582.9881656804733\" cy=\"398.98397435897425\" r=\"2.5\"/><desc class=\"value\">0.5066</desc><desc class=\"x left top\">582.9881656804733</desc><desc class=\"y left top\">398.98397435897425</desc><desc class=\"x_label\">240</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"634.7633136094674\" cy=\"422.4479574098218\" r=\"2.5\"/><desc class=\"value\">0.4988</desc><desc class=\"x left top\">634.7633136094674</desc><desc class=\"y left top\">422.4479574098218</desc><desc class=\"x_label\">270</desc></g></g><g class=\"series serie-2 color-2\"><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"65.23668639053255\" cy=\"434.4807692307692\" r=\"2.5\"/><desc class=\"value\">0.4948</desc><desc class=\"x top\">65.23668639053255</desc><desc class=\"y top\">434.4807692307692</desc><desc class=\"x_label\">40</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"168.7869822485207\" cy=\"401.08971642764016\" r=\"2.5\"/><desc class=\"value\">0.5059</desc><desc class=\"x top\">168.7869822485207</desc><desc class=\"y top\">401.08971642764016</desc><desc class=\"x_label\">80</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"272.3372781065089\" cy=\"398.98397435897425\" r=\"2.5\"/><desc class=\"value\">0.5066</desc><desc class=\"x top\">272.3372781065089</desc><desc class=\"y top\">398.98397435897425</desc><desc class=\"x_label\">120</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"375.887573964497\" cy=\"389.65854519774\" r=\"2.5\"/><desc class=\"value\">0.5097</desc><desc class=\"x left top\">375.887573964497</desc><desc class=\"y left top\">389.65854519774</desc><desc class=\"x_label\">160</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"479.4378698224852\" cy=\"401.99217731421106\" r=\"2.5\"/><desc class=\"value\">0.5056</desc><desc class=\"x left top\">479.4378698224852</desc><desc class=\"y left top\">401.99217731421106</desc><desc class=\"x_label\">200</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"582.9881656804733\" cy=\"411.91924706649297\" r=\"2.5\"/><desc class=\"value\">0.5023</desc><desc class=\"x left top\">582.9881656804733</desc><desc class=\"y left top\">411.91924706649297</desc><desc class=\"x_label\">240</desc></g><g class=\"dots\"><circle class=\"dot reactive tooltip-trigger\" cx=\"686.5384615384615\" cy=\"398.98397435897425\" r=\"2.5\"/><desc class=\"value\">0.5066</desc><desc class=\"x left top\">686.5384615384615</desc><desc class=\"y left top\">398.98397435897425</desc><desc class=\"x_label\">280</desc></g></g></g><g class=\"plot text-overlay\" transform=\"translate(80, 46)\"><g class=\"series serie-0 color-0\"/><g class=\"series serie-1 color-1\"/><g class=\"series serie-2 color-2\"/></g><g class=\"plot tooltip-overlay\" transform=\"translate(80, 46)\"><g class=\"tooltip\" style=\"opacity: 0\" transform=\"translate(0 0)\"><rect class=\"tooltip-box\" height=\"0\" rx=\"0\" ry=\"0\" width=\"0\"/><g class=\"text\"/></g></g><g class=\"legends\" transform=\"translate(90, 555)\"><g class=\"legend reactive activate-serie\" id=\"activate-serie-0\"><rect class=\"color-0 reactive\" height=\"12\" width=\"12\" x=\"0.0\" y=\"1.0\"/><text x=\"17.0\" y=\"11.2\">TableBERT</text></g><g class=\"legend reactive activate-serie\" id=\"activate-serie-1\"><rect class=\"color-1 reactive\" height=\"12\" width=\"12\" x=\"350.0\" y=\"1.0\"/><text x=\"367.0\" y=\"11.2\">Frozen_TableBERT_1</text></g><g class=\"legend reactive activate-serie\" id=\"activate-serie-2\"><rect class=\"color-2 reactive\" height=\"12\" width=\"12\" x=\"0.0\" y=\"22.0\"/><text x=\"17.0\" y=\"32.2\">Frozen_TableBERT_2</text></g></g></g></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "line_cart_2 = pygal.Line(legend_at_bottom=True)\n",
    "line_cart_2.title = 'Dev Accuracy over Minutes'\n",
    "line_cart_2.x_labels = list(joint_time_performance[\"Minutes Taken\"])\n",
    "line_cart_2.x_title = \"Minutes\"\n",
    "line_cart_2.y_title = \"Dev Accuracy\"\n",
    "line_cart_2.add(\"TableBERT\", [x if not pd.isna(x) else None for x in joint_time_performance[\"TableBERT\"]])\n",
    "line_cart_2.add(\"Frozen_TableBERT_1\", [x if not pd.isna(x) else None for x in joint_time_performance[\"Frozen_TableBERT_1\"]])\n",
    "line_cart_2.add(\"Frozen_TableBERT_2\", [x if not pd.isna(x) else None for x in joint_time_performance[\"Frozen_TableBERT_2\"]])\n",
    "display(SVG(line_cart_2.render(disable_xml_declaration=True)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit hard to look into this as the two experiments are not showing performance any better than random, so instead here are some of the examples that regular TableBERT gets right vs wrong. After going through them, there is no real trend that I can find (which is also mentioned) in the paper, as sometimes TableBERT gets really easy things wrong  and some hard things right. However, in general the simpler the statement is to verify (i.e. using only one row of information) the easier it is for TableBERT to do a good job. \n",
    "\n",
    "Note: Statements have been lemmatized and parsed for UNK words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples from TableBERT:**\n",
    "\n",
    "**Simpler Claims:**\n",
    "\n",
    "*Table:* [Second table found here](https://en.wikipedia.org/wiki/Australia_and_the_United_Nations)\n",
    "\n",
    "*Examples gotten Correct:*\n",
    "\n",
    "Claim: australia 's role as military advisor be in the un operation unam (True)\n",
    "\n",
    "Claim: 65 australian be involve in the un in 1992 - 1993 (False)\n",
    "\n",
    "*Examples gotten Wrong:*\n",
    "\n",
    "Claim: australia 's role in the un operation un consular commission be as military advisor (False)\n",
    "\n",
    "Claim: 65 australian be involve in the un advance mission in cambodia from 1991 - 199 (True)\n",
    "\n",
    "**More Complex Claims:**\n",
    "\n",
    "*Table:* [1st table found here](https://en.wikipedia.org/wiki/2000_United_States_presidential_election_in_Nevada)\n",
    "\n",
    "*Examples gotten Correct:*\n",
    "\n",
    "Claim: clark county have the narrowest margin between gore and bush during the \\[UNK\\] (True)\n",
    "\n",
    "Claim: during the \\[UNK\\] gore win only 1 county \\[UNK\\] lincoln county with 51.3% of the vote (False)\n",
    "\n",
    "*Examples gotten Wrong:*\n",
    "\n",
    "Claim: pershing county have the narrowest margin between gore and bush during the \\[UNK\\] (False)\n",
    "\n",
    "Claim: for the state of \\[UNK\\] the independent candidate during the \\[UNK\\] receive the most vote in humboldt county (False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In conclusion if one is trying to build a more efficient version of TableBERT, one must take one of the following options, as simply using BERT as an encoder and then adding a linear classifier at the end is not enough to take advantage of the possability of BERT's transfer learning in this statement entailment task:\n",
    "\n",
    "1. Use a more complex classifier on top of BERT's encodings\n",
    "2. Train some of the layers of BERT, i.e. don't freeze all of them\n",
    "3. Change the methodology of converting a table into a sequence\n",
    "\n",
    "The two experiments I ran were neither more efficient in terms of number of labels or time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
